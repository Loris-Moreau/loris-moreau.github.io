<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Optimizing a Raytracer</title>
    <link rel="icon" type="image/x-icon" href="../Images/RayTracing/computeShaderRenderCornellSmol.webp">

    <!-- Meta Tags for SEO -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Loris Moreau">
    <meta name="description" content="Raytracing Blog">
    <meta name="keywords" content="Showcase, Loris, Moreau, Loris Moreau, Programmer, coding adventure, Blog, Post, Raytracing, C++, CPP, Raytracing in one weekend, Optimization, optimized, optimizing, Compute, shaders, Compute Shader, multi threading, Hyper threading, SIMD, optimizing a raytracer, raytracer optimization, efficient raytracing, efficient raytracer, optimized raytracing, improving raytracer performance, performance">

    <!-- Styles -->
    <link rel="stylesheet" href="../Styles/style.css">
    <link rel="stylesheet" href="../Styles/Code-Quote.css">

    <script src="../Scripts/Carousel.js" defer></script>

    <style>
        /* Quote Element */
        .quote {
            background: dimgrey;
            padding: 1px 6px;
            margin: 0 2px;
            border-radius: 5px;
            font-size: 0.97rem;
        }
    </style>
</head>

<body>

<main id="BlogPost" class="post">
    <header>
        <!-- Navbar -->
        <nav style="margin: 0 auto 2em auto;">
            <ul>
                <li><a href="../Blog.html">Back</a></li>
                <li><a href="../index.html" target="_blank">Main</a></li>
                <li><a href="../Blog.html" target="_blank">Blog</a></li>
                <li><a href="../Resources.html" target="_blank">Resources</a></li>
            </ul>
        </nav>

        <!-- Top showcase + intro -->
        <div class="flex-container">
            
            <img height="400px" loading="lazy" src="../Images/RayTracing/Final%20Render%20high-Res%20(B2).webp" alt="Final Render of Book 2">
            
            <div class="text-container">
                <h1>Optimizing Raytracing in one weekend in C++</h1>
                
                <p></p>
                
                <p>
                    <a href="https://github.com/Loris-Moreau/RayTracing/tree/Compute-Shader" target="_blank">GitHub Repository</a>
                    · 
                    <a href="https://github.com/Loris-Moreau/RayTracing/blob/Compute-Shader/Performance.md" target="_blank">Performance Document</a>
                    · 
                    <a href="RayTracing-10_Bibliography.html" target="_blank">Bibliography</a>
                </p>
            </div>
        </div>
    </header>
    
    <!-- Section: Intro / Overview -->
    <section>
        <h2 class="underline" style="text-decoration-color: dodgerblue">Optimization, Multithreading, SIMD & Compute Shaders</h2>

        <h3>I'm Currently doing a research project & the theme I've chosen for myself is "<i class="underline" style="text-decoration-color: green">Optimization</i>".</h3>
        <p>
            After finishing the <a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html" target="_blank">1st book</a> 
            from Peter Shirley’s <a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html" target="_blank">Ray Tracing in One Weekend</a> series
            I realized render times were a huge <strong>bottleneck</strong>,
            and as I went through the <a href="https://raytracing.github.io/books/RayTracingTheNextWeek.html" target="_blank">2nd book</a> it only got worse, 
            the final render I did took 5 Hrs and was still quite noisy <i>(not good)</i>,
            so this research project will look into <strong>optimization techniques</strong> for a raytracer to reduce render time and enable more samples & bounces.
        </p>
        
        <p><a href="#SIMD">- SIMD</a> <i>(<a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data" target="_blank">explanation</a>)</i></p>
        <p><a href="#MultiThreading">- Multithreading</a> <i>(<a href="https://en.wikipedia.org/wiki/Multithreading_(computer_architecture)" target="_blank">explanation</a>)</i></p>
        <p><a href="#Compute">- Compute Shaders</a> <i>(<a href="https://www.khronos.org/opengl/wiki/Compute_Shader" target="_blank">explanation</a>)</i></p>

        <p>The goal is to Parallelize the existing raytracing code to dramatically cut render times <i>(it's annoying but doable)</i>.</p>
        <p>Each of these should shorten render times by quite a bit and allow us to use more samples & bounces.</p>
    </section>

    <!-- Section: State of the art -->
    <section>
        <h2 class="underline" style="text-decoration-color: cadetblue">State of the art</h2>

        <p>We’ll build on the C++ code from Peter Shirley’s <a href="https://raytracing.github.io" target="_blank">Ray Tracing in One Weekend</a> series.</p>
        <p>Several community ports already implement & extend the raytracer : </p>
        <p>- <a href="https://github.com/utilForever/ray-tracing-in-one-weekend-cpp" target="_blank">utilForever’s C++17 repo</a></p>
        <p>- <a href="https://github.com/r1walz/cuda-ray-tracing-in-one-weekend" target="_blank">CUDA adaptation</a> parallelizing the raytracer.</p>

        <p>
            On the algorithmic side, <a href="https://blog.jyotiprakash.org/data-level-parallelism" target="_blank">data-level parallelism</a>
            research highlights <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data" target="_blank">SIMD</a>
            <i>(Single Instruction, Multiple Data)</i> to leverage hardware vector units and process many data elements in a single instruction.
        </p>

        <p>
            More reading about data-level parallelism :
            <a href="https://www.cs.umd.edu/~meesh/411/CA-online/chapter/exploiting-data-level-parallelism/index.html" target="_blank">"exploiting Data Level Parallelism"</a>
            and <a href="https://passlab.github.io/CSE564/notes/lecture20_DLP_Vector.pdf" target="_blank">"Data Level Parallelism Lecture"</a>.
        </p>

        <p>
            At a higher level, <a href="https://en.wikipedia.org/wiki/Multithreading_(computer_architecture)" target="_blank">multithreading</a> frameworks go
            from simple work-queue models to <a href="https://en.wikipedia.org/wiki/Grand_Central_Dispatch" target="_blank">Apple’s Grand Central Dispatch</a>
            further accelerating renders by distributing pixel-level tasks across multiple CPU cores.
        </p>

        <p>
            <a href="https://en.wikipedia.org/wiki/Amdahl_law" target="_blank">Amdahl’s Law</a> state that :
            <strong>
                <i class="quote">"the overall performance improvement gained by optimizing a single part of a system is limited by the fraction of time that the improved part is actually used"</i>.
            </strong>
        </p>

        <p>
            Finally, modern GPUs expose <a href="https://www.khronos.org/opengl/wiki/Compute_Shader" target="_blank">Compute Shaders</a> <i>(With OpenGL 4.3+ HLSL/DX11+ kernels)</i>
            that enable massive parallelism outside the traditional rasterization pipeline,
            allowing us to offload raytracing workloads directly onto graphics hardware with thousands of concurrent threads.
        </p>

        <p></p>
        
        <h3>Our starting point will be the final render of the <a href="https://raytracing.github.io/books/RayTracingTheNextWeek.html" target="_blank">2nd book</a>.</h3>
        <figure>
            <img loading="lazy" src="../Images/RayTracing/Final%20Render%20high-Res%20(B2).webp" alt="Final Render of Book 2" style="width: 55%; padding-bottom: 5px;" />
            <figcaption><a href="https://github.com/Loris-Moreau/RayTracing/blob/main/Images/Final%20Render%20high-Res%20(B2).webp" target="_blank">img. Source</a></figcaption>
        </figure>
    </section>

    <!-- SIMD Section -->
    <section>
        <h2 id="SIMD" class="underline" style="text-decoration-color: royalblue; padding-bottom: 7px">SIMD</h2>

        <p>"Single instruction, multiple data <i>(SIMD)</i> is a type of parallel processing in
            <a href="https://en.wikipedia.org/wiki/Flynn%27s_taxonomy" target="_blank">Flynn's taxonomy</a>.
        </p>
        <p>SIMD describes computers with multiple processing elements that perform the same operation on multiple data points simultaneously.</p>
        <p>
            SIMD can be internal <i>(part of the hardware design)</i> and it can be directly accessible through an
            <a href="https://en.wikipedia.org/wiki/Instruction_set_architecture" target="_blank">instruction set architecture</a> <i>(ISA)</i>,
            but it should not be confused with an ISA."
        </p>
        <h4><a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data" target="_blank">Source.</a></h4>

        <p>SIMD is basically operations on arrays, like so :</p>
        <figure>
            <img loading="lazy" src="../Images/RayTracing/SIMD-operation.webp" alt="SISD vs SIMD Operations" style="width: 65%; padding-bottom: 5px;" />
            <figcaption><a href="https://blog.wasmer.io/webassembly-and-simd-13badb9bf1a8" target="_blank">img. Source</a></figcaption>
        </figure>
        <p></p>
        <p><a href="https://medium.com/@bromanz/simd-sse-unity3d-net-2-0-70f6c911713f" target="_blank">SIMD use in Unity3D</a></p>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Things to Remember : </h2>
        <p>- If you're using the correct memory layouts when implementing SIMD, the rest of the problems will solve themselves.</p>
        <p>- Parallel performance largely depends on the extent to which your program is parallelized.</p>
        <p>- Compiling code with the <strong class="quote">-march=native</strong> flag generates optimized code for your CPU.</p>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">How do we achieve this ?</h2>
        <p>SIMD is not a computation problem, it's simply a memory layout problem.</p>
        <p>
            To make our sphere data "SIMD-friendly", we could use the
            <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/memory-layout-transformations.html" target="_blank">Structure of Arrays (SoA)</a>
            where each field is stored in its own array.
        </p>
        <p>
            SoA excels when you frequently access only a subset of a struct’s members, each cache line then holds just the data you need,
            leading to significant gains in performance.
        </p>

        <p>
            Instead, we use an
            <a href="https://www.intel.com/content/www/us/en/developer/articles/technical/memory-layout-transformations.html" target="_blank">Array of Structures of Arrays (AoSoA)</a>
            layout. In AoSoA, each field is still an array, but its length matches the SIMD lane width <i>(<strong class="quote">LANE_WIDTH</strong>)</i>.
        </p>

        <p>
            If we have more spheres than fit in one SIMD vector, we simply add another “lane” <i>(another fixed-size chunk)</i> to our AoSoA.
        </p>

        <p>
            This way, each chunk maps perfectly onto SIMD registers, maximizing both alignment and throughput.
        </p>
        <p>Like so : </p>

        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title">
                    <p>SIMD.h</p>
                </div>
                <div class="Sconsole">
      <pre><code>// Wide vector3 struct
struct LaneVector3
{
    LaneF32 x;
    LaneF32 y;
    LaneF32 z;

    LaneVector3();
    LaneVector3(LaneF32 x, LaneF32 y, LaneF32 z);
    LaneVector3(float arr[3][LANE_WIDTH]);
    LaneVector3(Vector3 vector);

    LaneF32& operator[](int index);
};</code></pre>
                </div>
            </div>
        </div>

        <p>Here is a good <a href="https://www.youtube.com/watch?v=0_Byw9UMn9g" target="_blank">video</a> about this problem.</p>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Amdahl's Law</h2>
        <p>We are not gaining as much as we should from SIMD & SSE operations, <i>but why ?</i></p>
        <p>
            <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law" target="_blank">Amdahl's Law</a>
            states that the overall speedup from parallelization is limited by the portion of the program that must remain serial.
        </p>
        <p>In our case, 50% of execution time is spent in the Intersection function.</p>
        <p>As the chart below illustrates, no matter how many cores or SIMD lanes we employ, the maximum achievable speedup caps at 2x.</p>
        <p>This explains why using a 4-lane vector unit doesn't yield a 4x performance gain.</p>

        <figure>
            <img loading="lazy" src="../Images/RayTracing/AmdahlsLaw.webp" alt="Amdahl's Law" style="width: 65%; padding-bottom: 5px;" />
            <figcaption><a href="https://en.wikipedia.org/wiki/Amdahl_law" target="_blank">img. Source</a></figcaption>
        </figure>

        <p>With SIMD we managed to cut render time in 2.</p>

        <h2 style="padding-bottom: 5px">Final recorded Time :</h2>
        <p style="padding-bottom: 0"><strong class="quote">case 10: FinalSceneB2(600, 200, 100, 20, 250) :</strong></p>
        <p style="padding-top: 0; padding-bottom: 0"><strong class="quote">- Non-Optimized : 5 Hrs</strong></p>
        <p  style="padding-top: 0; padding-bottom: 0"><strong class="quote">- SIMD Optimized : 2 Hrs 18 Min</strong></p>
    </section>

    <!-- Multithreading Section -->
    <section>
        <h2 id="MultiThreading" class="underline" style="text-decoration-color: royalblue; padding-bottom: 7px">MultiThreading</h2>

        <h4>"Multithreading is a form of parallelization or dividing up work for simultaneous processing.</h4>
        <h4>Instead of giving a large workload to a single core, threaded programs split the work into multiple software threads.</h4>
        <h4>These threads are processed in parallel by different CPU cores to save time."</h4>
        <h4><a href="https://www.intel.com/content/www/us/en/gaming/resources/hyper-threading.html#articleparagraph_cop" target="_blank">Source.</a></h4>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Things to Remember : </h2>
        <p>
            As this <a href="https://fgiesen.wordpress.com/2013/01/31/cores-dont-like-to-share/" target="_blank">blog by rygorous</a> states :
        </p>
        <p>
            After writing shared data, other threads must throw all the work,
            retrieve the latest value of the variable since the cached version is no longer valid,
            and then restart their tasks.
            This phenomenon is referred to as "<a href="https://en.wikipedia.org/wiki/False_sharing" target="_blank">false sharing</a>".
        </p>
        <p>Here is an interesting video talking about <a href="https://www.youtube.com/watch?v=WDIkqP4JbkE" target="_blank">Cpu Caches</a>.</p>
        
        <p></p>
        
        <figure>
            <img loading="lazy" src="../Images/RayTracing/40-years-processor-trend.webp" alt="40 Years Processor Trend" style="width: 75%; padding-bottom: 5px;" />
            <figcaption><a href="https://www.karlrupp.net/2015/06/40-years-of-microprocessor-trend-data" target="_blank">img. Source</a></figcaption>
        </figure>

        <h5>If you're in computer science you've probably seen this image or a variation of it.</h5>
        <p>
            This image shows us that, although transistor counts continue to climb in a somewhat linear fashion, 
            the era of ever-increasing single-threaded processor speeds is effectively over.
            As a matter of fact, as the gains in single-core performance have tapered off, chip designers have responded by packing ever more logical cores onto each die.
        </p>
        <p>
            The takeaway is that if your application relies on a purely single-threaded workload, you’ll see diminishing returns on the latest CPUs.
            To harness their full power, you must divide your work across multiple cores.
        </p>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Breaking a Program into Parallel Tasks : </h2>
        <p>
            To exploit multiple CPU threads, you first need to
            <a href="https://softwareengineering.stackexchange.com/questions/82582/best-way-to-break-down-overwhelming-code-into-manageable-chunks" target="_blank">decompose your program</a>
            into independent pieces, <i>a notoriously tricky challenge in general</i>.
            Once you’ve done that, you then need to coordinate those pieces safely,
            <i>which often introduces <a href="https://stackoverflow.com/a/2860263" target="_blank">overhead</a></i>.
            Fortunately, ray-tracing is a textbook example of an
            “<a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel" target="_blank">embarrassingly parallel</a>” problem :
        </p>
        <p>- each pixel in the final image can be computed in isolation.</p>

        <p>
            We are calculating each pixel. And almost every pixel is independent, so synchronization will be minimal.
            The cores are going to render each pixel independently, and when all the pixels are done, we put it all together into the final image.
        </p>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Lock-Free Synchronization with Atomics</h2>
        <p>
            I’ve been looking into <a href="https://learn.microsoft.com/en-us/windows/win32/dxtecharts/lockless-programming" target="_blank">lockless</a> programming techniques,
            <i>
                (<a href="https://preshing.com/20120612/an-introduction-to-lock-free-programming/" target="_blank">intro to lock free programming</a> &
                <a href="https://www.reddit.com/r/cpp/comments/vg4myt/is_lockfree_programming_is_always_better_than/" target="_blank">an interesting talk about Lock-free vs Mutex</a>)
            </i>,
            & how compilers and CPUs <a href="https://en.wikipedia.org/wiki/Memory_ordering" target="_blank">reorder memory operations</a>,
            the differences between various architectures, and so on.
        </p>

        <p>
            While traditional mutexes are often the easiest way to guard shared data, I plan to use atomic instructions instead, so threads never block one another,
            since Lock-free programming is only for some rare use cases, typically with lots of threads meeting at the same variable.
        </p>

        <p>
            In the context of this ray-tracer project where synchronization needs are minimal I believe an atomic-based approach will be straightforward and more performant.
        </p>

        <p>
            We could spawn one thread per image row and leverage
            <a href="https://en.wikipedia.org/wiki/Grand_Central_Dispatch" target="_blank">Apple’s Grand Central Dispatch</a> <i>(GCD)</i>.
            which lets you easily multi-thread your loop using the <strong class="quote">dispatch_apply</strong> function,
            GCD automatically distributes iterations across all available threads and waits until they're all complete, with no manual synchronization needed.
        </p>

        <p>Ultimately, though, we're going to use the simple work-queue approach from <a href="https://www.youtube.com/watch?v=ZAeU3Z0PmcU" target="_blank">Handmade Ray</a>.</p>
        <p>We package units of work into <i>“orders”</i> and push them onto a queue. Each thread continuously fetches and executes orders,
            if the queue is empty, the thread idles until new work appears.
        </p>

        <h4>A little something like this :</h4>
        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>Work Queue</p></div>
                <div class="Sconsole">
      <pre><code>struct WorkOrder 
{
    Image* image;
    World* world;
    uint32_t startRowIndex;
    uint32_t endRowIndex;
    uint32_t sampleSize;
    uint32_t* randomState;
};

struct WorkQueue 
{
    uint32_t workOrderCount;
    WorkOrder* workOrders;

    volatile uint64_t nextOrderToDo;
    volatile uint64_t finishedOrderCount;
    volatile uint64_t totalBouncesComputed;
};

bool RaytraceWork(WorkQueue* workQueue) 
{
    uint32_t nextOrderToDo = InterlockedAddAndReturnPrevious(&workQueue->nextOrderToDo, 1);
    if (nextOrderToDo >= workQueue->workOrderCount) 
    {
        return false;
    }
    
    fetch the next WorkOrder
    
    ...
    raytracing
    ...
    
    InterlockedAddAndReturnPrevious(&workQueue->totalBouncesComputed, totalBounces);
    InterlockedAddAndReturnPrevious(&workQueue->finishedOrderCount, 1);
    
    return true;
}</code></pre>
                </div>
            </div>
        </div>

        <p>
            In the end we managed to boost render time by roughly 2x for renders using Multithreading.
        </p>

        <h2 style="padding-bottom: 5px">Final recorded Time :</h2>
        <p style="padding-bottom: 0"><strong class="quote">case 10: FinalSceneB2(600, 200, 100, 20, 250) :</strong></p>
        <p style="padding-top: 0; padding-bottom: 0"><b class="quote">- Non-Optimized : 5 Hrs</b></p>
        <p  style="padding-top: 0; padding-bottom: 0"><b class="quote">- Multithreading Optimized : 2 Hrs 9 Min</b></p>
    </section>

    <!-- Compute Shader Section -->
    <section>
        <h2 id="Compute" class="underline" style="text-decoration-color: royalblue; padding-bottom: 7px">Compute Shaders</h2>

        <h4>"A compute shader provides high-speed general purpose computing and takes advantage of the large numbers of parallel processors on the graphics processing unit (GPU).</h4>
        <h4>The compute shader provides memory sharing and thread synchronization features to allow more effective parallel programming methods."</h4>
        <h4><a href="https://learn.microsoft.com/en-us/windows/win32/direct3d11/direct3d-11-advanced-stages-compute-shader" target="_blank">Source.</a></h4>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px" id="ttrcs">Things to Remember : </h2>
        <p>Base Raytracing code & Compute shader code aren't that far apart, so it's not too hard to transfer one to the other just annoying.</p>
        <p>
            One of the issues with GPU porting is that <strong>GLSL doesn't map memory into zeros</strong>.
            You should be aware that it doesn't have a constructor that we use in C++ for filling struct memory with zeros
        </p>
        <p>
            <b>you should also beware of <a href="https://learn.microsoft.com/en-us/cpp/cpp/alignment-cpp-declarations?view=msvc-170" target="_blank">alignment</a></b>
            since it was one of the main causes for a black screen, When using UBO or SSBO.
        </p>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">But How ?</h2>
        <p>The point of this is to transfer the raytracer to the GPU, and since our code is already broken into parts it shouldn't be much of a hassle to transfer it into GPU.</p>
        <p>
            The compute shader is going to do the same work that the CPU is doing.
            Then it is going to produce the image as a texture object and send that texture into the fragment shader.
        </p>
        <p>That fragment shader is then going to <a href="https://en.wikipedia.org/wiki/Gamma_correction" target="_blank">gamma correct</a> the image and render it to the screen.</p>

        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>fragment.glsl</p></div>
                <div class="Sconsole">
      <pre><code>#version 450 core

in vec2 texCoord;

uniform sampler2D image;

out vec4 finalColor;

#define Clamp(A, c, B) clamp(c, A, B)

float LinearTosRGB(in float value) {
    value = Clamp(0.0f, value, 1.0f);

    float result = value * 12.92f;
    if (value >= 0.0031308f) {
        result = (1.055f * pow(value, 1.0f / 2.4f)) - 0.055f;
    }

    return result;
}

vec3 LinearVectorTosRGBVector(in vec3 value) {
    vec3 result;

    result.x = LinearTosRGB(value.x);
    result.y = LinearTosRGB(value.y);
    result.z = LinearTosRGB(value.z);

    return result;
}

void main () {
    vec3 rawColor = texture(image, texCoord).xyz;
    finalColor = vec4(LinearVectorTosRGBVector(rawColor), 1.0);
}</code></pre>
                </div>
            </div>
        </div>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Buffers</h2>
        <p>When it comes to writing shaders, shader languages closely resemble C++, so you can often paste your ray-tracer code directly into a shader file.</p>
        <p>The only differences are in data type names and some built-in function names, so beware of that, or you could make a macro to map them to the CPU versions.</p>
        <p>
            One challenge is how to supply scene data to the compute shader,
            GLSL offers two main buffer types for this :
        </p>
        <p>- <a href="https://www.khronos.org/opengl/wiki/Uniform_Buffer_Object" target="_blank">Uniform Buffer Objects (UBOs)</a> for small, fast-access data</p>
        <p>- <a href="https://www.khronos.org/opengl/wiki/Shader_Storage_Buffer_Object" target="_blank">Shader Storage Buffer Objects (SSBOs)</a> for larger datasets.</p>
        <p>
            We're going to go with SSBOs because they allow variable-length arrays, this will let us pass scene elements without pre-defining a fixed size.
            In practice, you should declare an SSBO in GLSL like this:
        </p>

        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>SSBO</p></div>
                <div class="Sconsole">
                    <pre><code>layout(shared, binding = 0) buffer MaterialBuffer {
    Material gMaterials[]; // Variable size array
};</code></pre>
                </div>
            </div>
        </div>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Alignment</h2>
        <p>So that went well, but there is another problem <i>(I mentioned this <a href="#ttrcs">above</a>)</i>. The alignment of SSBO structs is not the same as C++ ones.</p>
        <p>According to the <a href="https://community.khronos.org/t/interpretation-of-std140-layout" target="_blank">OpenGL specification</a> : </p>
        <p><i>"(9) If the member is a structure, the base alignment of the structure is &ltN>, where &ltN> is the largest base alignment value of any of its members, ..."</i></p>
        <p>In our case, we have vec3 in our structs. Size of vec3 is 12 bytes but vec3 count as vec4.
            So our alignment for structs should be 16. This can be done in many ways. You can put padding data into the structs,
        </p>
        <p>Or we can define offsets and tweak layout properties using the
            <a href="https://registry.khronos.org/OpenGL/extensions/ARB/ARB_enhanced_layouts.txt" target="_blank">enhanced layout extension</a>.</p>

        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>Material</p></div>
                <div class="Sconsole">
                    <pre><code>struct Material 
{
    // These two can be bundled as a vec4. First three component for color and the last one is for refractiveIndex;
    Vector3 color;
    float refractiveIndex;

    // These two as well
    Vector3 emitColor;
    float reflection; 
};</code></pre>
                </div>
            </div>
        </div>

        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>GLSL Material</p></div>
                <div class="Sconsole">
                    <pre><code>struct Material 
{
    // In GLSL, all the vec3 type variables are aligned to 16 bytes (vec4). 
    // We can use extra float padding with the enhanced layout extension.
    // layout(component = 3) means w component of vec4 holds this value.
    vec3 color;
    layout(component = 3) float refractiveIndex;
    vec3 emitColor;
    layout(component = 3) float reflection; 
};</code></pre>
                </div>
            </div>
        </div>

        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>Align Material struct in CPP</p></div>
                <div class="Sconsole">
                    <pre><code>// Align these struct members to 16 byte.
__declspec(align(16)) struct Material 
{
    Vector3 color;
    float refractiveIndex;
    Vector3 emitColor;
    float reflection; 
};</code></pre>
                </div>
            </div>
        </div>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Checking for Errors</h2>
        <p>When we write an OpenGL app we will often see thing we don't like <i>(e.g. black screen, white screen, crash, etc...)</i></p>
        <p>so we need to find these errors by creating our OpenGL context with
            <a href="https://www.khronos.org/opengl/wiki/OpenGL_Error#Catching_errors_(the_easy_way)" target="_blank">debugging properties</a>.</p>
        <p>We can check for errors by calling
            <a href="https://registry.khronos.org/OpenGL-Refpages/gl4/html/glGetError.xhtml" target="_blank">glGetError()</a> after each OpenGL function.
        </p>
        
        <p>like so:  <i>(the following code is by 
            <a href="https://blog.nobel-joergensen.com/2013/02/17/debugging-opengl-part-2-using-gldebugmessagecallback/" target="_blank">Morten Nobel-Jørgensen</a>)</i> :
        </p>
        
        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>OpenGL Callback Function</p></div>
                <div class="Sconsole">
                    <pre><code>void APIENTRY openglCallbackFunction(GLenum source, GLenum type, GLuint id, GLenum severity, GLsizei length,
                                            const GLchar* message, const void* userParam)
{
    std::cout << "---------------------opengl-callback-start------------" << '\n';
    std::cout << "message: "<< message << '\n';
    std::cout << "type: ";
    switch (type) 
    {
    case GL_DEBUG_TYPE_ERROR:
        std::cout << "ERROR";
        break;
    case GL_DEBUG_TYPE_DEPRECATED_BEHAVIOR:
        std::cout << "DEPRECATED_BEHAVIOR";
        break;
    case GL_DEBUG_TYPE_UNDEFINED_BEHAVIOR:
        std::cout << "UNDEFINED_BEHAVIOR";
        break;
    case GL_DEBUG_TYPE_PORTABILITY:
        std::cout << "PORTABILITY";
        break;
    case GL_DEBUG_TYPE_PERFORMANCE:
        std::cout << "PERFORMANCE";
        break;
    case GL_DEBUG_TYPE_OTHER:
        std::cout << "OTHER";
        break;
    }
    std::cout << '\n';

    std::cout << "id: " << id << '\n';
    std::cout << "severity: ";
    switch (severity)
    {
    case GL_DEBUG_SEVERITY_LOW:
        std::cout << "LOW";
        break;
    case GL_DEBUG_SEVERITY_MEDIUM:
        std::cout << "MEDIUM";
        break;
    case GL_DEBUG_SEVERITY_HIGH:
        std::cout << "HIGH";
        break;
    }
    std::cout << '\n';
    std::cout << "---------------------opengl-callback-end--------------" << '\n';
}</code></pre>
                </div>
            </div>
        </div>

        <p>
            One of the big error we get is "Long Running Execution" or
            <a href="https://docs.nvidia.com/gameworks/index.html#developertools/desktop/timeout_detection_recovery.htm" target="_blank">TDR</a>,
            here is a <a href="https://youtu.be/VaGcs5-W6S4?si=6lnOD9yTl6ejm3Rn" target="_blank">video</a> talking about GPU crash debugging by Nvidia
            as well as this <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/display/timeout-detection-and-recovery" target="_blank">article</a> by microsoft
            that talks about TDR and what steps to take to resolve it.
        </p>

        <p>
            Basically what TDR does is :
            "<a href="https://docs.nvidia.com/gameworks/index.html#developertools/desktop/timeout_detection_recovery.htm" target="_blank">If the operating system does not receive
                a response from a graphics card within a certain amount of time <i>(default is 2 sec)</i>, the operating system resets the graphics card.</a>",
            so we just reduce the sample size, and it works again !!
        </p>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Progressive Rendering</h2>
        <p>what is <a href="https://blog.cloudflare.com/parallel-streaming-of-progressive-images/#what-is-progressive-image-rendering" target="_blank">Progressive Rendering</a> ?</p>
        <p>First we render a very low quality sampled image and then progressively refining it as more samples are accumulated.</p>
        <p>Let's add that behavior : on each frame, we’ll blend in the newly rendered image with the running average to gradually improve quality.</p>
        <p>Something like this : </p>

        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>Progressive Rendering</p></div>
                <div class="Sconsole">
                    <pre><code>// First image.
layout(rgba32f, location = 0) readonly uniform image2D srcImage;
// Output image.
layout(rgba32f, location = 1) writeonly uniform image2D destImage;
...
// Number of frames averaged
layout(location = 4) uniform uint32_t frameIndex;

...

// Calculate the sum of all the previous samples
Vector3 sumColor = prevColor * frameIndex;
// Add new color to sum, then re-average it.
Vector3 finalColor = (color + sumColor) / (frameIndex + 1);

imageStore(destImage, pix, vec4(finalColor, 1.0));</code></pre>
                </div>
            </div>
        </div>

        <h2 class="underline" style="text-decoration-color: cadetblue; padding-bottom: 10px">Performance</h2>
        <p>OpenGL supports <a href="https://www.khronos.org/opengl/wiki/Atomic_Counter" target="_blank">Atomic Counters</a>,
            so we could count the ray bounces, or we could use SSBO again for the counter, then use
            <a href="https://registry.khronos.org/OpenGL-Refpages/gl4/html/atomicAdd.xhtml" target="_blank">naive atomic add operation</a>,
            after the compute shader finished its job, you map the bounce count to SSBO so you can read the bounce count.</p>
        <p>Both of these have roughly the same performance, so you can use either, I will use the second method, like so :</p>

        <div class="snippet">
            <div class="Swindow">
                <div class="Swindow-title"><p>Atomic Operations</p></div>
                <div class="Sconsole">
                    <pre><code>layout(binding = 3) buffer Counter { 
    uint32_t gBounceCount; 
};
...
atomicAdd(gBounceCount, totalBounces);

// C++ code
glBindBuffer(GL_SHADER_STORAGE_BUFFER, bounceCountSSBO);
uint32_t* counter = (uint32_t*) glMapBuffer(GL_SHADER_STORAGE_BUFFER, GL_READ_ONLY);
bounceCount = counter[0];
glUnmapBuffer(GL_SHADER_STORAGE_BUFFER);</code></pre>
                </div>
            </div>
        </div>
        
        <p></p>
        
        <figure>
            <img loading="lazy" src="../Images/RayTracing/computeShaderRenderCornell.webp" alt="SISD vs SIMD Operations" style="width: 75%; padding-bottom: 5px;" />
            <figcaption><b class="underline" style="text-decoration-color: limegreen; text-decoration-thickness: 2px">Render time :</b> regular = 30mins; compute shaders = 1min
                <br><a href="https://github.com/Loris-Moreau/RayTracing/blob/Compute-Shader/Images/computeShaderRenderCornell.webp" target="_blank">img. Source</a></figcaption>
        </figure>
        
        <p></p>
        
        <figure>
            <img loading="lazy" src="../Images/RayTracing/computeShaderRenderB2.webp" alt="SISD vs SIMD Operations" style="width: 75%; padding-bottom: 5px;" />
            <figcaption><b class="underline" style="text-decoration-color: limegreen; text-decoration-thickness: 2px">Render time :</b> regular = 5hrs; compute shaders = 30sec
                <br><a href="https://github.com/Loris-Moreau/RayTracing/blob/Compute-Shader/Images/computeShaderRenderB2.webp" target="_blank">img. Source</a></figcaption>
        </figure>

        <p>
            With Compute Shaders it's 10x faster for quads and even more for spheres,
            <i>(and this is simply porting the original raytracer code into compute shaders, we haven't actually optimized anything, (apart from a few SIMD Lanes))</i>.
        </p>

        <h2 style="padding-bottom: 5px">Final recorded Time :</h2>
        <p style="padding-bottom: 0"><b class="quote">case 10: FinalSceneB2(600, 200, 100, 20, 250) :</b></p>
        <p style="padding-top: 0; padding-bottom: 0"><b class="quote">- Non-Optimized : 5 Hrs</b></p>
        <p  style="padding-top: 0; padding-bottom: 0"><b class="quote">- Compute Shader Optimized : 30 sec</b></p>
        
        <h5>Damn I knew it was going to be way faster but this is <b>WAY faster</b>.</h5>
    </section>

    <!-- Conclusion -->
    <section>
        <h2 class="underline" style="text-decoration-color: royalblue; padding-bottom: 10px">Conclusion</h2>
        <p>
            In the end SIMD & Multithreading are good optimization techniques but cap at 2x due to Amdahl's Law,
            while compute shader will go as fast as the computer can <i>(logical cores)</i>.
        </p>
        <p>So I think it's best to put what you can in compute shaders, and the rest in SIMD using Lanes and wide vectors.</p>
        <p>Just don't forget that each of these techniques can and can't do certain things
            <i>(e.g. compute shaders can't do everything we still need actions to execute outside)</i></p>
        <p>This is the final approach I have for my  <a href="https://github.com/Loris-Moreau/RayTracing/tree/Compute-Shader" target="_blank">implementation</a>.</p>
        
        <p><a href="RayTracing-10_Bibliography.html" target="_blank">Bibliography</a></p>

        <p>See you some other time.</p>
    </section>

    <footer>
        <p style="color: var(--text-color-bright);">07-05-2025</p>
    </footer>
</main>

<!-- Navigation buttons -->
<div style="text-align:center; margin-top:1rem">
    <a href="RayTracing-9.html" class="cta-button">Previous</a>
    <a href="../Blog.html" class="cta-button secondary">Entries</a>
    <a href="VFX-1.html" class="cta-button">Next</a>
</div>

</body>
</html>
